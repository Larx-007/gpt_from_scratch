{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "636c1944",
   "metadata": {},
   "source": [
    "# Transformer model (GPT) from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5cb510",
   "metadata": {},
   "source": [
    "GPT (Not \"THE ChatGPT\") is a Large Language Model (LLM) made by OpenAI back in 2018. Its architecture is based on the decoder-based transformer model from [Attention Is All You Need](https://arxiv.org/pdf/1706.03762) paper.\n",
    "\n",
    "- Why a Language Model? -> Bcoz it just predicts and generates the next word for a given input sequence of words.\n",
    "- Why not \"THE ChatGPT\"? -> Bcoz its just a text generator, not someone to chat with. ChatGPT is a conversational app built on top of GPT. \n",
    "- Why Large? -> Bcoz its basically a large neural network with millions (billions for SOTA models) of parameters.\n",
    "\n",
    "We will rather train a simpler and smaller model of our own.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5382104",
   "metadata": {},
   "source": [
    "### But why transformers?\n",
    "\n",
    "Earlier RNN based language models like GRU or LSTM process text word-by-word due to which they faced challenges like:\n",
    "- long-term memory loss as information from the beginning of a long sentence often fades or gets lost (\"vanishing gradient problem\") by the time the model reaches the end.\n",
    "- were very slow to train or infer due to their sequential nature of processing.  \n",
    "\n",
    "Transformer model solved these problems by leveraging attention mechanism which mathematically is just a matrix multiplication thus allowing parallel processing of entire text sequence at once. This enables self-attention to look at all the words in the sequence at the same time for getting context.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af2b112",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
