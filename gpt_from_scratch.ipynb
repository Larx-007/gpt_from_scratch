{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7eda5d7d",
      "metadata": {
        "id": "7eda5d7d"
      },
      "source": [
        "# Transformer model (GPT) from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dab2472d",
      "metadata": {
        "id": "dab2472d"
      },
      "source": [
        "GPT (Not \"THE ChatGPT\") is a Large Language Model (LLM) made by OpenAI back in 2018. Its architecture is based on the decoder-based transformer model from [Attention Is All You Need](https://arxiv.org/pdf/1706.03762) paper.\n",
        "\n",
        "- Why a Language Model? -> Bcoz it just predicts and generates the next word for a given input sequence of words.\n",
        "- Why not \"THE ChatGPT\"? -> Bcoz its just a text generator, not someone to chat with. ChatGPT is a conversational app built on top of GPT.\n",
        "- Why Large? -> Bcoz its basically a large neural network with millions (billions for SOTA models) of parameters.\n",
        "\n",
        "We will rather train a simpler and smaller model of our own.\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c704522",
      "metadata": {
        "id": "2c704522"
      },
      "source": [
        "### But why transformers?\n",
        "\n",
        "Earlier RNN based language models like GRU or LSTM process text word-by-word due to which they faced challenges like:\n",
        "- long-term memory loss as information from the beginning of a long sentence often fades or gets lost (\"vanishing gradient problem\") by the time the model reaches the end.\n",
        "- were very slow to train or infer due to their sequential nature of processing.  \n",
        "\n",
        "Transformer model solved these problems by leveraging attention mechanism which mathematically is just a matrix multiplication thus allowing parallel processing of entire text sequence at once. This enables self-attention to look at all the words in the sequence at the same time for getting context.\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21439371",
      "metadata": {
        "id": "21439371"
      },
      "source": [
        "### 1. Dataset preparation"
      ]
    },
    {
      "attachments": {
        "bpe_example.png": {
          "image/png": "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"
        }
      },
      "cell_type": "markdown",
      "id": "de5d3c36",
      "metadata": {
        "id": "de5d3c36"
      },
      "source": [
        "Models like GPTs were trained on massive internet data. We will use a simple and tiny dataset which basically consists of Shakespeare literature.\n",
        "\n",
        "Typical dataset preparation involves **tokenization**. It is the process of splitting a text sequence into samller chunks (like splitting a sentence into words) which are converted to numbers (integers) bcoz neural networks being a mathematical model (doing some matrix multiplications and additions) work with numbers. These numbers (or tokens) are what a language model takes as input and generates as output. Thus we  need to encode the text sequences into list of tokens for the input and decode the predicted tokens back to original text sequence for the textoutput.\n",
        "\n",
        "Tokenization itself is a hell of a process. Modern tokenization techniques use BPE (Byte Pair Encoding) algorithm which iteratively merges the most frequently occurring pairs of characters or bytes into new, single units producing sub-word tokens e.g. \"ing\", \"ment\", \"er\", etc.\n",
        "\n",
        "![bpe_example.png](attachment:bpe_example.png)\n",
        "\n",
        "Want to see it live, just click here ðŸ‘‰ [Tiktokenizer](https://tiktokenizer.vercel.app/).\n",
        "\n",
        "We will instead follow a simple tokenization process where we tokenize each character. Thus every unique character in the dataset will be considered as a single token. Thus our model will work with character-level tokens and once trained it will generate text character-by-character but in Shakespeare style."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "076873c3",
      "metadata": {
        "id": "076873c3"
      },
      "source": [
        "#### 1.1 Loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "76978aba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76978aba",
        "outputId": "c028f0e0-f4dd-4119-c340-f1aedf406346"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "with open(\"data/tiny_shakespeare.txt\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "print(text[:1000]) # first 1000 characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "219c660e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "219c660e",
        "outputId": "3069232b-1e4f-4302-a297-ea90df971412"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(text) # 1M+ character-level tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dfb5f25",
      "metadata": {
        "id": "7dfb5f25"
      },
      "source": [
        "#### 1.2 Creating vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e28adb83",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e28adb83",
        "outputId": "9d52d7b0-c33e-4b85-f835-5bc5966dbdbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "65\n"
          ]
        }
      ],
      "source": [
        "chars = sorted(set(''.join(text))) # getting all unique characters\n",
        "vocab_size = len(chars) # total unique characters/tokens\n",
        "print(chars)\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2abf6b6",
      "metadata": {
        "id": "f2abf6b6"
      },
      "source": [
        "#### 1.3 Creating encoder and decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c311bee3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c311bee3",
        "outputId": "a3e4c961-0348-44d1-a12b-fecfa4a5c9f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}\n",
            "{0: '\\n', 1: ' ', 2: '!', 3: '$', 4: '&', 5: \"'\", 6: ',', 7: '-', 8: '.', 9: '3', 10: ':', 11: ';', 12: '?', 13: 'A', 14: 'B', 15: 'C', 16: 'D', 17: 'E', 18: 'F', 19: 'G', 20: 'H', 21: 'I', 22: 'J', 23: 'K', 24: 'L', 25: 'M', 26: 'N', 27: 'O', 28: 'P', 29: 'Q', 30: 'R', 31: 'S', 32: 'T', 33: 'U', 34: 'V', 35: 'W', 36: 'X', 37: 'Y', 38: 'Z', 39: 'a', 40: 'b', 41: 'c', 42: 'd', 43: 'e', 44: 'f', 45: 'g', 46: 'h', 47: 'i', 48: 'j', 49: 'k', 50: 'l', 51: 'm', 52: 'n', 53: 'o', 54: 'p', 55: 'q', 56: 'r', 57: 's', 58: 't', 59: 'u', 60: 'v', 61: 'w', 62: 'x', 63: 'y', 64: 'z'}\n"
          ]
        }
      ],
      "source": [
        "# character to integer mappings\n",
        "ch_to_i = {ch: i for i, ch in enumerate(chars)}\n",
        "i_to_ch = {i: ch for i, ch in enumerate(chars)}\n",
        "print(ch_to_i)\n",
        "print(i_to_ch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d61482ca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "d61482ca",
        "outputId": "b5e4251e-264f-4a12-f1d3-0f08b98005b7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Hello World!'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# defining encoder and docoder\n",
        "encode = lambda str: [ch_to_i[ch] for ch in str] # takes a string -> returns list of integers/tokens\n",
        "decode = lambda ints: ''.join(i_to_ch[i] for i in ints) # takes a list of integers/tokens -> returns a string\n",
        "\n",
        "# testing\n",
        "decode(encode(\"Hello World!\")) # YEH! it works."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcf8c94f",
      "metadata": {
        "id": "bcf8c94f"
      },
      "source": [
        "#### 1.4 Converting tokens to a PyTorch tensor object\n",
        "\n",
        "Why tensor object? -> Bcoz models created using PyTorch use tensors as datatypes which not only store data but also store the gradients required for training optimization.\n",
        "\n",
        "***Note:** Here we are using `torch.long` data type for our tensor object. This is required in order to index embeddings from the embedding matrix that we will use later.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "fe7958f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe7958f7",
        "outputId": "b88c6936-fab7-4434-a2ca-340e0197f186"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1115394]) torch.int64\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
              "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
              "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
              "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
              "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
              "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# encode text to tokens and store into a torch.tensor object\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "data[:100] # first 100 tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4be96a9c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4be96a9c",
        "outputId": "d00d59b2-cec3-40c7-9a2e-b828390e4a51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First 10 characters (original): First Citi\n",
            "First 10 characters (tokenized): [18, 47, 56, 57, 58, 1, 15, 47, 58, 47]\n",
            "Character to token mapping:\n",
            "char = 'F' | token = 18\n",
            "char = 'i' | token = 47\n",
            "char = 'r' | token = 56\n",
            "char = 's' | token = 57\n",
            "char = 't' | token = 58\n",
            "char = ' ' | token = 1\n",
            "char = 'C' | token = 15\n",
            "char = 'i' | token = 47\n",
            "char = 't' | token = 58\n",
            "char = 'i' | token = 47\n"
          ]
        }
      ],
      "source": [
        "print(f\"First 10 characters (original): {text[:10]}\")\n",
        "print(f\"First 10 characters (tokenized): {data[:10].tolist()}\")\n",
        "print(\"Character to token mapping:\")\n",
        "for ch in list(text[:10]):\n",
        "    print(f\"char = '{ch}' | token = {ch_to_i[ch]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cea94620",
      "metadata": {
        "id": "cea94620"
      },
      "source": [
        "#### 1.5 Spitting dataset\n",
        "\n",
        "We use 90% of our data for training (to tune model parameters) and 10% for validation (to tune hyperparameters)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e784fe85",
      "metadata": {
        "id": "e784fe85"
      },
      "outputs": [],
      "source": [
        "# splitting data into training & validation sets\n",
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n] # 90% of data for training\n",
        "val_data = data[n:] # 10% of data for validation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9cb4f19",
      "metadata": {
        "id": "b9cb4f19"
      },
      "source": [
        "#### 1.6 Defining context length\n",
        "\n",
        "Context length is the maximum no. tokens given as input to the model. Larger context length allows more tokens to be fed into the model thus the model can have more context while predicting next token.\n",
        "\n",
        "It is a hyperparameter, means its value needs to be emperically set to tune model performance.\n",
        "\n",
        "We will start with a context length of 8. This means that for the given 8 characters (or tokens as we are using character level tokens) as input our model will predict the 9th token as output. We can gradually scale it up once we are confident of our model implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8d38649f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d38649f",
        "outputId": "f4bf9b0b-a7af-4f8e-93a7-6bc13bfbd2fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# defining context length\n",
        "block_size = 8\n",
        "train_data[:block_size+1] # block size is the max input sequence, +1 is the target"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4ba343d",
      "metadata": {
        "id": "f4ba343d"
      },
      "source": [
        "Training on all 8 individual examples is not only efficient but also helps the model adapt to predicting output during inference for the given input sequence of any length between 1 to block size."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5382c72",
      "metadata": {
        "id": "d5382c72"
      },
      "source": [
        "#### 1.7 Visualising input sequence and targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "756a96b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "756a96b5",
        "outputId": "31c19b27-9239-44c8-c013-a587f63a4c1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "when input is 'F' the target is 'i'\n",
            "when input is 'Fi' the target is 'r'\n",
            "when input is 'Fir' the target is 's'\n",
            "when input is 'Firs' the target is 't'\n",
            "when input is 'First' the target is ' '\n",
            "when input is 'First ' the target is 'C'\n",
            "when input is 'First C' the target is 'i'\n",
            "when input is 'First Ci' the target is 't'\n"
          ]
        }
      ],
      "source": [
        "# Visualizing 8 individual examples packed within the sequence of 9 characters as raw text\n",
        "x = text[:block_size] # inputs\n",
        "y = text[1:block_size+1] # targets\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1]\n",
        "    target = y[t]\n",
        "    print(f\"when input is '{context}' the target is '{target}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7751781f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7751781f",
        "outputId": "3bea3a5c-643f-4a99-c3ba-e770876949e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "when input is [18] the target is 47\n",
            "when input is [18, 47] the target is 56\n",
            "when input is [18, 47, 56] the target is 57\n",
            "when input is [18, 47, 56, 57] the target is 58\n",
            "when input is [18, 47, 56, 57, 58] the target is 1\n",
            "when input is [18, 47, 56, 57, 58, 1] the target is 15\n",
            "when input is [18, 47, 56, 57, 58, 1, 15] the target is 47\n",
            "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target is 58\n"
          ]
        }
      ],
      "source": [
        "# Visualizing 8 individual examples packed within the sequence of 9 characters as tokens\n",
        "x = train_data[:block_size] # inputs\n",
        "y = train_data[1:block_size+1] # targets\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1]\n",
        "    target = y[t]\n",
        "    print(f\"when input is {context.tolist()} the target is {target}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1221a5a5",
      "metadata": {
        "id": "1221a5a5"
      },
      "source": [
        "#### 1.8 Creating batches\n",
        "\n",
        "Why batches? Training on entire dataset at once can be extremely slow especially if the model is too large (compute intensive).   Instead training on random subsets of data is faster.\n",
        "\n",
        "A single batch contains ***batch size*** no. of example sequences each with `context length = block size` stacked up together into a tensor. Each sequence in the batch will be processed parallelly by the GPU. Each sequence contains 8 individual examples.\n",
        "\n",
        "So for `batch size = 4` and `block size = 8`, there are 32 examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2517c7f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2517c7f3",
        "outputId": "af3e1573-db5b-4260-a98e-645f77f0baed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device = cuda\n",
            "inputs:\n",
            "torch.Size([4, 8])\n",
            "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
            "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
            "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
            "        [25, 17, 27, 10,  0, 21,  1, 54]], device='cuda:0')\n",
            "targets:\n",
            "torch.Size([4, 8])\n",
            "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
            "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
            "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
            "        [17, 27, 10,  0, 21,  1, 54, 39]], device='cuda:0')\n",
            "--------------------------------------------------------------\n",
            "when input is [24] the target is 43\n",
            "when input is [24, 43] the target is 58\n",
            "when input is [24, 43, 58] the target is 5\n",
            "when input is [24, 43, 58, 5] the target is 57\n",
            "when input is [24, 43, 58, 5, 57] the target is 1\n",
            "when input is [24, 43, 58, 5, 57, 1] the target is 46\n",
            "when input is [24, 43, 58, 5, 57, 1, 46] the target is 43\n",
            "when input is [24, 43, 58, 5, 57, 1, 46, 43] the target is 39\n",
            "--------------------------------------------------------------\n",
            "when input is [44] the target is 53\n",
            "when input is [44, 53] the target is 56\n",
            "when input is [44, 53, 56] the target is 1\n",
            "when input is [44, 53, 56, 1] the target is 58\n",
            "when input is [44, 53, 56, 1, 58] the target is 46\n",
            "when input is [44, 53, 56, 1, 58, 46] the target is 39\n",
            "when input is [44, 53, 56, 1, 58, 46, 39] the target is 58\n",
            "when input is [44, 53, 56, 1, 58, 46, 39, 58] the target is 1\n",
            "--------------------------------------------------------------\n",
            "when input is [52] the target is 58\n",
            "when input is [52, 58] the target is 1\n",
            "when input is [52, 58, 1] the target is 58\n",
            "when input is [52, 58, 1, 58] the target is 46\n",
            "when input is [52, 58, 1, 58, 46] the target is 39\n",
            "when input is [52, 58, 1, 58, 46, 39] the target is 58\n",
            "when input is [52, 58, 1, 58, 46, 39, 58] the target is 1\n",
            "when input is [52, 58, 1, 58, 46, 39, 58, 1] the target is 46\n",
            "--------------------------------------------------------------\n",
            "when input is [25] the target is 17\n",
            "when input is [25, 17] the target is 27\n",
            "when input is [25, 17, 27] the target is 10\n",
            "when input is [25, 17, 27, 10] the target is 0\n",
            "when input is [25, 17, 27, 10, 0] the target is 21\n",
            "when input is [25, 17, 27, 10, 0, 21] the target is 1\n",
            "when input is [25, 17, 27, 10, 0, 21, 1] the target is 54\n",
            "when input is [25, 17, 27, 10, 0, 21, 1, 54] the target is 39\n"
          ]
        }
      ],
      "source": [
        "# creating batches\n",
        "torch.manual_seed(1337)\n",
        "batch_size = 4 # how many independent sequences will we process in parallel?\n",
        "block_size = 8 # what is the maximum context length for making a prediction?\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu' # use gpu if available\n",
        "\n",
        "print(f\"device = {device}\")\n",
        "\n",
        "def get_batch(split):\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data)-block_size, size=(batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[(i+1):(i+1)+block_size] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print(\"inputs:\")\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print(\"targets:\")\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "for b in range(batch_size):\n",
        "    print(\"--------------------------------------------------------------\")\n",
        "    for t in range(block_size):\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b, t]\n",
        "        print(f\"when input is {context.tolist()} the target is {target}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c29341dc",
      "metadata": {
        "id": "c29341dc"
      },
      "source": [
        "___\n",
        "### 2. Bigram model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc9b77a8",
      "metadata": {
        "id": "fc9b77a8"
      },
      "source": [
        "We will first start with super simple bigram langauge model that uses a lookup table to get the **logits** *(raw model outputs on which we will apply softmax to get probability distribution)* for making a prediction.\n",
        "\n",
        "> A bigram langauge model basically predicts the next char/word in a sequence only on the the basis of last char/word. Basically it just looks at the very last char/word of the sequence to get context when making predictions for the next char/word.\n",
        "\n",
        "A character-level bigram language model usually counts the frequencies for all possible character pairs from the dataset and store into a counts table like below:\n",
        "| |a|b|c|...|z|\n",
        "|-|-|-|-| - |-|\n",
        "|a|2|13|4|...|0|\n",
        "|b|24|7|1|...|0|\n",
        "|c|5|5|0|...|2|\n",
        "|...|...|...|...|...|...|\n",
        "|z|5|0|1|...|1|\n",
        "\n",
        "with each cell having the count for character pairs. For any input character the model just gets the whole row to get frequency counts for all possible pairs starting with that input character. Then the model just calculates probabilities from those counts and select a next character.\n",
        "\n",
        "Since we are using neural networks, instead of counting and storing character pair frequencies into a table we will use a simple lookup table (or embedding matrix) of same dimensions and expect its parameters to learn the values similar to the count values during training.\n",
        "\n",
        "This model will serve as the baseline for our transformer model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3ca3135",
      "metadata": {
        "id": "b3ca3135"
      },
      "source": [
        "#### 2.1 Defining code structure\n",
        "\n",
        "We will use Pytorch `nn.Module` to define our language model class. Our class will have 3 methods:\n",
        "1. `__init__` method: to initialize the module parameters\n",
        "2. `forward` method: which will take the inputs and return the logits and the loss\n",
        "3. `generate` method: to generate new tokens for the max limit\n",
        "\n",
        "The implementation of the ***generate*** method in this model seems irrelevant as its taking a sequence of tokens within a batch as input but only the last token in the sequence is being used for the prediction. Its intuitive that a bigram model only needs a single input token to predict the next token but here its taking a sequence of tokens. This is done with a purpose to have a similar implementation of the method for the later transformer model which will consider the history of tokens instead of just the last token to predict the next token in the sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6828a6e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6828a6e0",
        "outputId": "a3723cf1-541d-4ef5-f31d-17a3dc5a1ec6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 65])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "class BasicGPT(nn.Module):\n",
        "\tdef __init__(self):\n",
        "\t\tsuper().__init__()\n",
        "\t\t# each token directly reads off the logits for the next token from a lookup table\n",
        "\t\tself.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "\tdef forward(self, idx, targets=None):\n",
        "\t\t# idx (inputs) and targets are both (B, T) tensor of integers\n",
        "\t\tlogits = self.token_embedding_table(idx) # (B, T, C)\n",
        "\t\tloss = None\n",
        "\t\tif targets is not None:\n",
        "\t\t\t# Re-shaping is required to conform dimensions for calculating F.cross_entropy\n",
        "\t\t\tB, T, C = logits.shape\n",
        "\t\t\tlogits = logits.view(B*T, C)\n",
        "\t\t\ttargets = targets.view(B*T)\n",
        "\t\t\tloss = F.cross_entropy(logits, targets)\n",
        "\t\treturn logits, loss\n",
        "\n",
        "\tdef generate(self, idx, max_new_tokens):\n",
        "\t\t# idx (inputs) is of shape (B, T)\n",
        "\t\tfor _ in range(max_new_tokens):\n",
        "\t\t\t# get predictions\n",
        "\t\t\tlogits, loss = self(idx) # (B, T, C)\n",
        "\t\t\t# focus only on the last time step or the last value in the sequence within the batch\n",
        "\t\t\tlogits = logits[:, -1, :] # becomes (B, C)\n",
        "\t\t\t# apply softmax to get probabilities along the last dim i.e. C\n",
        "\t\t\tprobs = F.softmax(logits, dim=-1) # (B, C)\n",
        "\t\t\t# sample from the distribution to get next prediction in the sequence\n",
        "\t\t\tidx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "\t\t\t# append sampled index to the running sequence\n",
        "\t\t\tidx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "\n",
        "\t\treturn idx\n",
        "\n",
        "\n",
        "model = BasicGPT().to(device)\n",
        "logits, loss = model(xb, yb)\n",
        "print(logits.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14bcc90e",
      "metadata": {
        "id": "14bcc90e"
      },
      "source": [
        "___\n",
        "Inputs have the shape of (B, T) containing B*T individual examples.\n",
        "\n",
        "Logits have shape of (B, T, C) where B represents the batch dimension, T represents the time/sequence dimension and C represents the no. of channels or classes.\n",
        "\n",
        "For the given dimension values:  \n",
        "B = batch_size = 4,  \n",
        "T = block_size = 8,  \n",
        "C = vocab_size = 65  \n",
        "\n",
        "**Original:**\n",
        "logits.shape = [4, 8, 65]  \n",
        "**After reshaping (during loss calulation):**\n",
        "logits.shape = [32, 65]  \n",
        "\n",
        "In the `generate` method, the logits shape is (B, T, C) but since we are predicting next token based on the logits given by last token only, the shape changes to (B, C).\n",
        "\n",
        "For every batch out of 4 batches, for last token in the sequence -> take the all 65 logits (or embeddings since we are directly indexing them from the table as of now):  \n",
        "b1 [t1, t2, t3, t4, t5, t6, t7, `t8`]  \n",
        "b2 [t1, t2, t3, t4, t5, t6, t7, `t8`]  \n",
        "b3 [t1, t2, t3, t4, t5, t6, t7, `t8`]  \n",
        "b4 [t1, t2, t3, t4, t5, t6, t7, `t8`]  \n",
        "where `t8` has 65 values corresponding to each character in the vocabulary. Thus the shape changes to (B, C).\n",
        "\n",
        "***Note:** Even though we are providing 8 tokens as context still our prediction is solely based on the logits given by last token becoz there is no shared context or no communication is happening among the tokens as of now. Every token is independently indexing its own set of logits directly from the embedding matrix. Thus the logits produced for the last token got the context for only that token.*\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "4e301292",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e301292",
        "outputId": "f0ceaa40-03a0-46bc-a9d6-3b499d708e41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Expected probability: 0.015384615384615385\n",
            "Observed probability: 0.01053521316498518\n",
            "Expected initial loss: 4.174387454986572\n",
            "Observed initial loss: 4.878634929656982\n"
          ]
        }
      ],
      "source": [
        "probs = F.softmax(logits, dim=-1)\n",
        "observed_mean_prob = probs[torch.arange(32), yb.view(-1)].mean()\n",
        "\n",
        "print(f\"Expected probability: {1/65}\")\n",
        "print(f\"Observed probability: {observed_mean_prob}\")\n",
        "print(\"Expected initial loss:\", -torch.log(torch.tensor(1/65)).item())\n",
        "print(\"Observed initial loss:\", loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "687fe8f8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "687fe8f8",
        "outputId": "27cdfb97-b8f1-404b-ff22-c1c7b0177bc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text generation at random model params (no training):\n",
            "pYCXxfRkRZd\n",
            "wc'wfNfT;OLlTEeC K\n",
            "jxqPToTb?bXAUG:C-SGJO-33SM:C?YI3a\n",
            "hs:LVXJFhXeNuwqhObxZ.tSVrddXlaSZaNe\n"
          ]
        }
      ],
      "source": [
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "output = decode(model.generate(context, max_new_tokens=100)[0].tolist())\n",
        "print(f\"Text generation at random model params (no training):{output}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0e3a74d",
      "metadata": {
        "id": "c0e3a74d"
      },
      "source": [
        "___\n",
        "**Generation:** As of now the model generates gibberish bcoz the model is just randomly initialized. The model needs to learn to align its neurons in a sematically correct way in order to make any sensible output. This will improve after training.\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd3aca55",
      "metadata": {
        "id": "dd3aca55"
      },
      "source": [
        "#### 2.2 Training our bigram model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "9334c986",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9334c986",
        "outputId": "c3587f3c-a6d6-4659-cd5c-334d73155584"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device = cuda\n",
            "step 0: train loss 4.7305, val loss 4.7241\n",
            "step 300: train loss 2.8110, val loss 2.8249\n",
            "step 600: train loss 2.5434, val loss 2.5682\n",
            "step 900: train loss 2.4932, val loss 2.5088\n",
            "step 1200: train loss 2.4863, val loss 2.5035\n",
            "step 1500: train loss 2.4665, val loss 2.4921\n",
            "step 1800: train loss 2.4683, val loss 2.4936\n",
            "step 2100: train loss 2.4696, val loss 2.4846\n",
            "step 2400: train loss 2.4638, val loss 2.4879\n",
            "step 2700: train loss 2.4738, val loss 2.4911\n",
            "step 2999: train loss 2.4613, val loss 2.4897\n",
            "\n",
            "------------------------------- GENERATION -------------------------------\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "CEThik brid owindakis b, bth\n",
            "\n",
            "HAPet bobe d e.\n",
            "S:\n",
            "O:3 my d?\n",
            "LUCous:\n",
            "Wanthar u qur, t.\n",
            "War dXENDoate awice my.\n",
            "\n",
            "Hastarom oroup\n",
            "Yowhthetof isth ble mil ndill, ath iree sengmin lat Heriliovets, and Win nghir.\n",
            "Swanousel lind me l.\n",
            "HAshe ce hiry:\n",
            "Supr aisspllw y.\n",
            "Hentofu n Boopetelaves\n",
            "MPOLI s, d mothakleo Windo whth eisbyo the m dourive we higend t so mower; te\n",
            "\n",
            "AN ad nterupt f s ar igr t m:\n",
            "\n",
            "Thin maleronth,\n",
            "Mad\n",
            "RD:\n",
            "\n",
            "WISo myrangoube!\n",
            "KENob&y, wardsal thes ghesthinin couk ay aney IOUSts I&fr y ce.\n",
            "J\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 32\n",
        "block_size = 8\n",
        "learning_rate = 1e-2\n",
        "max_iters = 3000\n",
        "eval_interval = 300\n",
        "eval_iters = 200\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "print(f\"device = {device}\")\n",
        "\n",
        "# loading text data\n",
        "with open('data/tiny_shakespeare.txt', 'r', encoding='utf-8') as f:\n",
        "\ttext = f.read()\n",
        "\n",
        "# here are all the unique characters that occur in this text\n",
        "chars = sorted(set(text))\n",
        "vocab_size = len(chars)\n",
        "\n",
        "# create character to integer / integer to character mappings\n",
        "stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "itos = {i: ch for i, ch in enumerate(chars)}\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "# encoding entire datset and storing it into a torch.tensor\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "\n",
        "# Splitting data in training and validation sets\n",
        "n = int(0.9*len(data)) # first 90% of data is for training, rest is for validation\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "# create batches\n",
        "def get_batch(split):\n",
        "\tdata = train_data if split == 'train' else val_data\n",
        "\tix = torch.randint(len(data)-block_size, size=(batch_size,))\n",
        "\tx = torch.stack([data[i:i+block_size] for i in ix])\n",
        "\ty = torch.stack([data[(i+1):(i+1)+block_size] for i in ix])\n",
        "\tx, y = x.to(device), y.to(device)\n",
        "\treturn x, y\n",
        "\n",
        "\n",
        "class BasicGPT(nn.Module):\n",
        "\tdef __init__(self):\n",
        "\t\tsuper().__init__()\n",
        "\t\t# each token directly reads off the logits for the next token from a lookup table\n",
        "\t\tself.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "\tdef forward(self, idx, targets=None):\n",
        "\t\t# idx (inputs) and targets are both (B, T) tensor of integers\n",
        "\t\tlogits = self.token_embedding_table(idx) # (B, T, C)\n",
        "\t\tloss = None\n",
        "\t\tif targets is not None:\n",
        "\t\t\t# Re-shaping is required to conform dimensions for calculating F.cross_entropy\n",
        "\t\t\tB, T, C = logits.shape\n",
        "\t\t\tlogits = logits.view(B*T, C)\n",
        "\t\t\ttargets = targets.view(B*T)\n",
        "\t\t\tloss = F.cross_entropy(logits, targets)\n",
        "\t\treturn logits, loss\n",
        "\n",
        "\tdef generate(self, idx, max_new_tokens):\n",
        "\t\t# idx (inputs) is of shape (B, T)\n",
        "\t\tfor _ in range(max_new_tokens):\n",
        "\t\t\t# get predictions\n",
        "\t\t\tlogits, loss = self(idx) # (B, T, C)\n",
        "\t\t\t# focus only on the last time step or the last value in the sequence within the batch\n",
        "\t\t\tlogits = logits[:, -1, :] # becomes (B, C)\n",
        "\t\t\t# apply softmax to get probabilities along the last dim i.e. C\n",
        "\t\t\tprobs = F.softmax(logits, dim=-1) # (B, C)\n",
        "\t\t\t# sample from the distribution to get next prediction in the sequence\n",
        "\t\t\tidx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "\t\t\t# append sampled index to the running sequence\n",
        "\t\t\tidx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "\n",
        "\t\treturn idx\n",
        "\n",
        "\n",
        "model = BasicGPT().to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "\tout = {}\n",
        "\tmodel.eval()\n",
        "\tfor split in ['train', 'val']:\n",
        "\t\tlosses = torch.zeros(eval_iters)\n",
        "\t\tfor k in range(eval_iters):\n",
        "\t\t\txb, yb = get_batch(split)\n",
        "\t\t\tlogits, loss = model(xb, yb)\n",
        "\t\t\tlosses[k] = loss.item()\n",
        "\t\tout[split] = losses.mean()\n",
        "\tmodel.train()\n",
        "\treturn out\n",
        "\n",
        "\n",
        "for iter in range(max_iters):\n",
        "\t # every once in a while evaluate loss on train and val sets\n",
        "\tif iter % eval_interval == 0:\n",
        "\t\tlosses = estimate_loss()\n",
        "\t\tprint(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "\t# sample a batch\n",
        "\txb, yb = get_batch('train')\n",
        "\t# forward pass\n",
        "\tlogits, loss = model(xb, yb)\n",
        "\t# set gradients to None\n",
        "\toptimizer.zero_grad(set_to_none=True)\n",
        "\t# backward pass\n",
        "\tloss.backward()\n",
        "\t# update\n",
        "\toptimizer.step()\n",
        "\n",
        "losses = estimate_loss()\n",
        "print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "# generate from the model\n",
        "print(\"\\n------------------------------- GENERATION -------------------------------\\n\")\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(model.generate(context, max_new_tokens=500)[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23dfec63",
      "metadata": {
        "id": "23dfec63"
      },
      "source": [
        "#### 2.3 Baseline results\n",
        "\n",
        "**final loss:** train loss 2.4613, val loss 2.4897\n",
        "\n",
        "This is our baseline loss. We will try to surpass this loss with our transformer based implementation."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
